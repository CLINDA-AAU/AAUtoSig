{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86d5982",
   "metadata": {},
   "source": [
    "## DSAE Markdown\n",
    "This document is a runthrough of Peis autoencoder model.\n",
    "Firstly we initialise our installed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c822cc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mq:\\AUH-HAEM-FORSK-MutSigDLBCL222\\article_1\\scripts\\AAUtoSig\\DSAE.ipynb Cell 2'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/DSAE.ipynb#ch0000001?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/DSAE.ipynb#ch0000001?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/DSAE.ipynb#ch0000001?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Model \n\u001b[0;32m      <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/DSAE.ipynb#ch0000001?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense, Input, Dropout\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/DSAE.ipynb#ch0000001?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m regularizers\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=14'>15</a>\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=15'>16</a>\u001b[0m \n\u001b[0;32m     <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=16'>17</a>\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=17'>18</a>\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=18'>19</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=19'>20</a>\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2\n\u001b[0;32m     <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=23'>24</a>\u001b[0m \u001b[39m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/tensorflow/__init__.py?line=33'>34</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/tensorflow/__init__.py?line=34'>35</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/tensorflow/__init__.py?line=36'>37</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/tensorflow/__init__.py?line=37'>38</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/tensorflow/__init__.py?line=39'>40</a>\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "from keras.models import Model \n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras import regularizers\n",
    "from functions import simulate_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e5bb6f",
   "metadata": {},
   "source": [
    "## Load and preprocess data\n",
    "Having confirmed that the mutation types are regarded as the rows and the patients are regarede as the columns in this problem, anlysis will be carried out on a simulated pentanucleotide dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc8a20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2780\n"
     ]
    }
   ],
   "source": [
    "nsigs = 5\n",
    "\n",
    "latent_dim = nsigs\n",
    "\n",
    "batch_size_n = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Pei makes a denoising, sparse autoencoder. This means that they add noise to the input data\n",
    "noise_factor = 0.01 \n",
    "\n",
    "#load data\n",
    "mf_df, true_sigs, _ = simulate_counts(5, 3000)\n",
    "penta = mf_df.index\n",
    "mutation = [p[3:6] for p in penta]\n",
    "\n",
    "#Pei standardises the input values by dividing by the max input value (maybe because all tutorials does this)\n",
    "max_val = mf_df.max().max()\n",
    "\n",
    "#Split data into test and train set\n",
    "test_set_percent = 0.2\n",
    "\n",
    "x_test = mf_df.sample(frac=test_set_percent)/max_val\n",
    "x_train = mf_df.drop(x_test.index)/max_val\n",
    "\n",
    "#Add normal noise\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size = x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size = x_test.shape)\n",
    "\n",
    "#clamp input data between 0 and 1. All entries are normalised such that mf.df = mf.df/max(mf.df)\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "\n",
    "#column dimension in input data\n",
    "original_dim = mf_df.shape[1]\n",
    "print(original_dim)\n",
    "\n",
    "print(mutation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae18276",
   "metadata": {},
   "source": [
    "# Define autoencoder\n",
    "The following block creates a class to initialize a one-hidden-layer linear autoencoder, and a method for traning the one such model. \n",
    "The first part defines a single fully-connected neural layer as encoder and as decoder that works for training, but also defines seperate encoding and decoding models. This is for weight extraction. All training takes place in the 'autoencoder'. This seems heavily inspired from https://blog.keras.io/building-autoencoders-in-keras.html  \n",
    "\n",
    "Calling keras.Model (or Model here) generates a NN where the forward pass is defined as the layers defined between the inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f32f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------- This defines the autoencoder --------------------------------------------\n",
    "# Compress from original_dim => latent_dim \n",
    "encoding_dim = latent_dim\n",
    "\n",
    "# this is our input placeholder\n",
    "input_dim = Input(shape=(original_dim,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation = \"relu\", activity_regularizer = regularizers.l1(1e-12))(input_dim)\n",
    "#This is where you would stack layers\n",
    "\n",
    "# \"decoded\" is the reconstruction of the input\n",
    "decoded = Dense(original_dim, activation = \"softmax\")(encoded)\n",
    "#This is where you would stack layers\n",
    "\n",
    "# autoencoder model - This model maps an input to its reconstruction\n",
    "autoencoder = Model(inputs = input_dim, outputs = decoded)\n",
    "\n",
    "\n",
    "# -------------------------------------------- Seperate encoder model --------------------------------------------\n",
    "# This model maps an input to its encoded representation\n",
    "encoder = Model(inputs = input_dim, outputs = encoded)\n",
    "\n",
    "\n",
    "# -------------------------------------------- Seperate decoder model --------------------------------------------\n",
    "# create a placeholder for the hidden layer\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "\n",
    "# create the decoder model\n",
    "decoder = Model( encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------- Compiler autoencoder --------------------------------------------\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad590644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 1.6879e-06 - val_loss: 1.3420e-06\n",
      "Epoch 2/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6879e-06 - val_loss: 1.3420e-06\n",
      "Epoch 3/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6879e-06 - val_loss: 1.3420e-06\n",
      "Epoch 4/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6879e-06 - val_loss: 1.3419e-06\n",
      "Epoch 5/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6879e-06 - val_loss: 1.3419e-06\n",
      "Epoch 6/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6879e-06 - val_loss: 1.3419e-06\n",
      "Epoch 7/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6879e-06 - val_loss: 1.3419e-06\n",
      "Epoch 8/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6879e-06 - val_loss: 1.3419e-06\n",
      "Epoch 9/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6879e-06 - val_loss: 1.3419e-06\n",
      "Epoch 10/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6879e-06 - val_loss: 1.3419e-06\n",
      "Epoch 11/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6879e-06 - val_loss: 1.3419e-06\n",
      "Epoch 12/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6879e-06 - val_loss: 1.3419e-06\n",
      "Epoch 13/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6879e-06 - val_loss: 1.3419e-06\n",
      "Epoch 14/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6879e-06 - val_loss: 1.3419e-06\n",
      "Epoch 15/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6878e-06 - val_loss: 1.3419e-06\n",
      "Epoch 16/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6878e-06 - val_loss: 1.3419e-06\n",
      "Epoch 17/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6878e-06 - val_loss: 1.3419e-06\n",
      "Epoch 18/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6878e-06 - val_loss: 1.3419e-06\n",
      "Epoch 19/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6878e-06 - val_loss: 1.3419e-06\n",
      "Epoch 20/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6878e-06 - val_loss: 1.3419e-06\n",
      "Epoch 21/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6878e-06 - val_loss: 1.3419e-06\n",
      "Epoch 22/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6878e-06 - val_loss: 1.3418e-06\n",
      "Epoch 23/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6878e-06 - val_loss: 1.3418e-06\n",
      "Epoch 24/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6878e-06 - val_loss: 1.3418e-06\n",
      "Epoch 25/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6878e-06 - val_loss: 1.3418e-06\n",
      "Epoch 26/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6878e-06 - val_loss: 1.3418e-06\n",
      "Epoch 27/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6878e-06 - val_loss: 1.3418e-06\n",
      "Epoch 28/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6877e-06 - val_loss: 1.3418e-06\n",
      "Epoch 29/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6877e-06 - val_loss: 1.3418e-06\n",
      "Epoch 30/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6877e-06 - val_loss: 1.3418e-06\n",
      "Epoch 31/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6877e-06 - val_loss: 1.3418e-06\n",
      "Epoch 32/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6877e-06 - val_loss: 1.3418e-06\n",
      "Epoch 33/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6877e-06 - val_loss: 1.3418e-06\n",
      "Epoch 34/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6877e-06 - val_loss: 1.3418e-06\n",
      "Epoch 35/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6877e-06 - val_loss: 1.3418e-06\n",
      "Epoch 36/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6877e-06 - val_loss: 1.3418e-06\n",
      "Epoch 37/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6877e-06 - val_loss: 1.3417e-06\n",
      "Epoch 38/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6877e-06 - val_loss: 1.3417e-06\n",
      "Epoch 39/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6876e-06 - val_loss: 1.3417e-06\n",
      "Epoch 40/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6876e-06 - val_loss: 1.3417e-06\n",
      "Epoch 41/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6876e-06 - val_loss: 1.3417e-06\n",
      "Epoch 42/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6876e-06 - val_loss: 1.3417e-06\n",
      "Epoch 43/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6876e-06 - val_loss: 1.3417e-06\n",
      "Epoch 44/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6876e-06 - val_loss: 1.3417e-06\n",
      "Epoch 45/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6876e-06 - val_loss: 1.3417e-06\n",
      "Epoch 46/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6876e-06 - val_loss: 1.3417e-06\n",
      "Epoch 47/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6876e-06 - val_loss: 1.3417e-06\n",
      "Epoch 48/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6876e-06 - val_loss: 1.3417e-06\n",
      "Epoch 49/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6876e-06 - val_loss: 1.3417e-06\n",
      "Epoch 50/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6875e-06 - val_loss: 1.3417e-06\n",
      "Epoch 51/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6875e-06 - val_loss: 1.3416e-06\n",
      "Epoch 52/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6875e-06 - val_loss: 1.3416e-06\n",
      "Epoch 53/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6875e-06 - val_loss: 1.3416e-06\n",
      "Epoch 54/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6875e-06 - val_loss: 1.3416e-06\n",
      "Epoch 55/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6875e-06 - val_loss: 1.3416e-06\n",
      "Epoch 56/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6875e-06 - val_loss: 1.3416e-06\n",
      "Epoch 57/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6875e-06 - val_loss: 1.3416e-06\n",
      "Epoch 58/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6875e-06 - val_loss: 1.3416e-06\n",
      "Epoch 59/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6875e-06 - val_loss: 1.3416e-06\n",
      "Epoch 60/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6875e-06 - val_loss: 1.3416e-06\n",
      "Epoch 61/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6874e-06 - val_loss: 1.3416e-06\n",
      "Epoch 62/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6874e-06 - val_loss: 1.3416e-06\n",
      "Epoch 63/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6874e-06 - val_loss: 1.3416e-06\n",
      "Epoch 64/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6874e-06 - val_loss: 1.3415e-06\n",
      "Epoch 65/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6874e-06 - val_loss: 1.3415e-06\n",
      "Epoch 66/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6874e-06 - val_loss: 1.3415e-06\n",
      "Epoch 67/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6874e-06 - val_loss: 1.3415e-06\n",
      "Epoch 68/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6874e-06 - val_loss: 1.3415e-06\n",
      "Epoch 69/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6874e-06 - val_loss: 1.3415e-06\n",
      "Epoch 70/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6874e-06 - val_loss: 1.3415e-06\n",
      "Epoch 71/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6873e-06 - val_loss: 1.3415e-06\n",
      "Epoch 72/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6873e-06 - val_loss: 1.3415e-06\n",
      "Epoch 73/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6873e-06 - val_loss: 1.3415e-06\n",
      "Epoch 74/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6873e-06 - val_loss: 1.3415e-06\n",
      "Epoch 75/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6873e-06 - val_loss: 1.3415e-06\n",
      "Epoch 76/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6873e-06 - val_loss: 1.3415e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6873e-06 - val_loss: 1.3414e-06\n",
      "Epoch 78/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6873e-06 - val_loss: 1.3414e-06\n",
      "Epoch 79/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6873e-06 - val_loss: 1.3414e-06\n",
      "Epoch 80/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6873e-06 - val_loss: 1.3414e-06\n",
      "Epoch 81/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6872e-06 - val_loss: 1.3414e-06\n",
      "Epoch 82/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6872e-06 - val_loss: 1.3414e-06\n",
      "Epoch 83/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6872e-06 - val_loss: 1.3414e-06\n",
      "Epoch 84/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6872e-06 - val_loss: 1.3414e-06\n",
      "Epoch 85/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6872e-06 - val_loss: 1.3414e-06\n",
      "Epoch 86/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6872e-06 - val_loss: 1.3414e-06\n",
      "Epoch 87/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6872e-06 - val_loss: 1.3414e-06\n",
      "Epoch 88/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6872e-06 - val_loss: 1.3414e-06\n",
      "Epoch 89/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6872e-06 - val_loss: 1.3413e-06\n",
      "Epoch 90/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6872e-06 - val_loss: 1.3413e-06\n",
      "Epoch 91/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6871e-06 - val_loss: 1.3413e-06\n",
      "Epoch 92/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6871e-06 - val_loss: 1.3413e-06\n",
      "Epoch 93/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6871e-06 - val_loss: 1.3413e-06\n",
      "Epoch 94/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6871e-06 - val_loss: 1.3413e-06\n",
      "Epoch 95/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6871e-06 - val_loss: 1.3413e-06\n",
      "Epoch 96/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6871e-06 - val_loss: 1.3413e-06\n",
      "Epoch 97/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6871e-06 - val_loss: 1.3413e-06\n",
      "Epoch 98/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6871e-06 - val_loss: 1.3413e-06\n",
      "Epoch 99/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6871e-06 - val_loss: 1.3413e-06\n",
      "Epoch 100/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6871e-06 - val_loss: 1.3413e-06\n",
      "Epoch 101/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6870e-06 - val_loss: 1.3412e-06\n",
      "Epoch 102/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6870e-06 - val_loss: 1.3412e-06\n",
      "Epoch 103/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6870e-06 - val_loss: 1.3412e-06\n",
      "Epoch 104/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6870e-06 - val_loss: 1.3412e-06\n",
      "Epoch 105/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6870e-06 - val_loss: 1.3412e-06\n",
      "Epoch 106/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6870e-06 - val_loss: 1.3412e-06\n",
      "Epoch 107/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6870e-06 - val_loss: 1.3412e-06\n",
      "Epoch 108/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6870e-06 - val_loss: 1.3412e-06\n",
      "Epoch 109/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6870e-06 - val_loss: 1.3412e-06\n",
      "Epoch 110/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6869e-06 - val_loss: 1.3412e-06\n",
      "Epoch 111/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6869e-06 - val_loss: 1.3412e-06\n",
      "Epoch 112/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6869e-06 - val_loss: 1.3412e-06\n",
      "Epoch 113/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6869e-06 - val_loss: 1.3411e-06\n",
      "Epoch 114/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6869e-06 - val_loss: 1.3411e-06\n",
      "Epoch 115/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6869e-06 - val_loss: 1.3411e-06\n",
      "Epoch 116/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6869e-06 - val_loss: 1.3411e-06\n",
      "Epoch 117/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6869e-06 - val_loss: 1.3411e-06\n",
      "Epoch 118/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6869e-06 - val_loss: 1.3411e-06\n",
      "Epoch 119/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6868e-06 - val_loss: 1.3411e-06\n",
      "Epoch 120/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6868e-06 - val_loss: 1.3411e-06\n",
      "Epoch 121/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6868e-06 - val_loss: 1.3411e-06\n",
      "Epoch 122/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6868e-06 - val_loss: 1.3411e-06\n",
      "Epoch 123/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6868e-06 - val_loss: 1.3411e-06\n",
      "Epoch 124/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6868e-06 - val_loss: 1.3411e-06\n",
      "Epoch 125/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6868e-06 - val_loss: 1.3410e-06\n",
      "Epoch 126/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6868e-06 - val_loss: 1.3410e-06\n",
      "Epoch 127/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6868e-06 - val_loss: 1.3410e-06\n",
      "Epoch 128/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6867e-06 - val_loss: 1.3410e-06\n",
      "Epoch 129/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6867e-06 - val_loss: 1.3410e-06\n",
      "Epoch 130/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6867e-06 - val_loss: 1.3410e-06\n",
      "Epoch 131/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6867e-06 - val_loss: 1.3410e-06\n",
      "Epoch 132/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6867e-06 - val_loss: 1.3410e-06\n",
      "Epoch 133/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6867e-06 - val_loss: 1.3410e-06\n",
      "Epoch 134/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6867e-06 - val_loss: 1.3410e-06\n",
      "Epoch 135/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6867e-06 - val_loss: 1.3410e-06\n",
      "Epoch 136/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6867e-06 - val_loss: 1.3409e-06\n",
      "Epoch 137/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6866e-06 - val_loss: 1.3409e-06\n",
      "Epoch 138/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6866e-06 - val_loss: 1.3409e-06\n",
      "Epoch 139/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6866e-06 - val_loss: 1.3409e-06\n",
      "Epoch 140/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6866e-06 - val_loss: 1.3409e-06\n",
      "Epoch 141/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6866e-06 - val_loss: 1.3409e-06\n",
      "Epoch 142/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6866e-06 - val_loss: 1.3409e-06\n",
      "Epoch 143/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6866e-06 - val_loss: 1.3409e-06\n",
      "Epoch 144/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6866e-06 - val_loss: 1.3409e-06\n",
      "Epoch 145/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6866e-06 - val_loss: 1.3409e-06\n",
      "Epoch 146/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6865e-06 - val_loss: 1.3409e-06\n",
      "Epoch 147/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6865e-06 - val_loss: 1.3409e-06\n",
      "Epoch 148/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6865e-06 - val_loss: 1.3408e-06\n",
      "Epoch 149/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6865e-06 - val_loss: 1.3408e-06\n",
      "Epoch 150/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6865e-06 - val_loss: 1.3408e-06\n",
      "Epoch 151/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6865e-06 - val_loss: 1.3408e-06\n",
      "Epoch 152/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6865e-06 - val_loss: 1.3408e-06\n",
      "Epoch 153/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6865e-06 - val_loss: 1.3408e-06\n",
      "Epoch 154/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6864e-06 - val_loss: 1.3408e-06\n",
      "Epoch 155/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6864e-06 - val_loss: 1.3408e-06\n",
      "Epoch 156/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6864e-06 - val_loss: 1.3408e-06\n",
      "Epoch 157/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6864e-06 - val_loss: 1.3408e-06\n",
      "Epoch 158/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6864e-06 - val_loss: 1.3408e-06\n",
      "Epoch 159/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6864e-06 - val_loss: 1.3407e-06\n",
      "Epoch 160/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6864e-06 - val_loss: 1.3407e-06\n",
      "Epoch 161/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6864e-06 - val_loss: 1.3407e-06\n",
      "Epoch 162/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6864e-06 - val_loss: 1.3407e-06\n",
      "Epoch 163/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6863e-06 - val_loss: 1.3407e-06\n",
      "Epoch 164/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6863e-06 - val_loss: 1.3407e-06\n",
      "Epoch 165/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6863e-06 - val_loss: 1.3407e-06\n",
      "Epoch 166/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6863e-06 - val_loss: 1.3407e-06\n",
      "Epoch 167/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6863e-06 - val_loss: 1.3407e-06\n",
      "Epoch 168/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6863e-06 - val_loss: 1.3407e-06\n",
      "Epoch 169/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6863e-06 - val_loss: 1.3406e-06\n",
      "Epoch 170/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6863e-06 - val_loss: 1.3406e-06\n",
      "Epoch 171/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6862e-06 - val_loss: 1.3406e-06\n",
      "Epoch 172/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6862e-06 - val_loss: 1.3406e-06\n",
      "Epoch 173/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6862e-06 - val_loss: 1.3406e-06\n",
      "Epoch 174/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6862e-06 - val_loss: 1.3406e-06\n",
      "Epoch 175/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6862e-06 - val_loss: 1.3406e-06\n",
      "Epoch 176/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6862e-06 - val_loss: 1.3406e-06\n",
      "Epoch 177/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6862e-06 - val_loss: 1.3406e-06\n",
      "Epoch 178/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6862e-06 - val_loss: 1.3406e-06\n",
      "Epoch 179/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6861e-06 - val_loss: 1.3406e-06\n",
      "Epoch 180/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6861e-06 - val_loss: 1.3405e-06\n",
      "Epoch 181/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6861e-06 - val_loss: 1.3405e-06\n",
      "Epoch 182/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6861e-06 - val_loss: 1.3405e-06\n",
      "Epoch 183/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6861e-06 - val_loss: 1.3405e-06\n",
      "Epoch 184/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6861e-06 - val_loss: 1.3405e-06\n",
      "Epoch 185/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6861e-06 - val_loss: 1.3405e-06\n",
      "Epoch 186/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6861e-06 - val_loss: 1.3405e-06\n",
      "Epoch 187/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6860e-06 - val_loss: 1.3405e-06\n",
      "Epoch 188/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6860e-06 - val_loss: 1.3405e-06\n",
      "Epoch 189/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6860e-06 - val_loss: 1.3405e-06\n",
      "Epoch 190/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6860e-06 - val_loss: 1.3404e-06\n",
      "Epoch 191/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6860e-06 - val_loss: 1.3404e-06\n",
      "Epoch 192/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6860e-06 - val_loss: 1.3404e-06\n",
      "Epoch 193/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6860e-06 - val_loss: 1.3404e-06\n",
      "Epoch 194/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6859e-06 - val_loss: 1.3404e-06\n",
      "Epoch 195/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6859e-06 - val_loss: 1.3404e-06\n",
      "Epoch 196/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6859e-06 - val_loss: 1.3404e-06\n",
      "Epoch 197/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6859e-06 - val_loss: 1.3404e-06\n",
      "Epoch 198/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6859e-06 - val_loss: 1.3404e-06\n",
      "Epoch 199/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6859e-06 - val_loss: 1.3404e-06\n",
      "Epoch 200/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6859e-06 - val_loss: 1.3403e-06\n",
      "Epoch 201/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6859e-06 - val_loss: 1.3403e-06\n",
      "Epoch 202/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6858e-06 - val_loss: 1.3403e-06\n",
      "Epoch 203/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6858e-06 - val_loss: 1.3403e-06\n",
      "Epoch 204/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6858e-06 - val_loss: 1.3403e-06\n",
      "Epoch 205/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6858e-06 - val_loss: 1.3403e-06\n",
      "Epoch 206/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6858e-06 - val_loss: 1.3403e-06\n",
      "Epoch 207/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6858e-06 - val_loss: 1.3403e-06\n",
      "Epoch 208/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6858e-06 - val_loss: 1.3403e-06\n",
      "Epoch 209/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6857e-06 - val_loss: 1.3403e-06\n",
      "Epoch 210/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6857e-06 - val_loss: 1.3402e-06\n",
      "Epoch 211/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6857e-06 - val_loss: 1.3402e-06\n",
      "Epoch 212/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6857e-06 - val_loss: 1.3402e-06\n",
      "Epoch 213/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6857e-06 - val_loss: 1.3402e-06\n",
      "Epoch 214/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6857e-06 - val_loss: 1.3402e-06\n",
      "Epoch 215/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6857e-06 - val_loss: 1.3402e-06\n",
      "Epoch 216/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6856e-06 - val_loss: 1.3402e-06\n",
      "Epoch 217/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6856e-06 - val_loss: 1.3402e-06\n",
      "Epoch 218/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6856e-06 - val_loss: 1.3402e-06\n",
      "Epoch 219/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6856e-06 - val_loss: 1.3401e-06\n",
      "Epoch 220/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6856e-06 - val_loss: 1.3401e-06\n",
      "Epoch 221/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6856e-06 - val_loss: 1.3401e-06\n",
      "Epoch 222/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6856e-06 - val_loss: 1.3401e-06\n",
      "Epoch 223/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6855e-06 - val_loss: 1.3401e-06\n",
      "Epoch 224/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6855e-06 - val_loss: 1.3401e-06\n",
      "Epoch 225/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6855e-06 - val_loss: 1.3401e-06\n",
      "Epoch 226/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6855e-06 - val_loss: 1.3401e-06\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6855e-06 - val_loss: 1.3401e-06\n",
      "Epoch 228/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6855e-06 - val_loss: 1.3401e-06\n",
      "Epoch 229/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6855e-06 - val_loss: 1.3400e-06\n",
      "Epoch 230/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6854e-06 - val_loss: 1.3400e-06\n",
      "Epoch 231/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6854e-06 - val_loss: 1.3400e-06\n",
      "Epoch 232/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6854e-06 - val_loss: 1.3400e-06\n",
      "Epoch 233/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6854e-06 - val_loss: 1.3400e-06\n",
      "Epoch 234/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6854e-06 - val_loss: 1.3400e-06\n",
      "Epoch 235/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6854e-06 - val_loss: 1.3400e-06\n",
      "Epoch 236/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6854e-06 - val_loss: 1.3400e-06\n",
      "Epoch 237/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6853e-06 - val_loss: 1.3400e-06\n",
      "Epoch 238/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6853e-06 - val_loss: 1.3399e-06\n",
      "Epoch 239/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6853e-06 - val_loss: 1.3399e-06\n",
      "Epoch 240/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6853e-06 - val_loss: 1.3399e-06\n",
      "Epoch 241/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6853e-06 - val_loss: 1.3399e-06\n",
      "Epoch 242/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6853e-06 - val_loss: 1.3399e-06\n",
      "Epoch 243/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6853e-06 - val_loss: 1.3399e-06\n",
      "Epoch 244/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6852e-06 - val_loss: 1.3399e-06\n",
      "Epoch 245/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6852e-06 - val_loss: 1.3399e-06\n",
      "Epoch 246/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6852e-06 - val_loss: 1.3399e-06\n",
      "Epoch 247/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6852e-06 - val_loss: 1.3398e-06\n",
      "Epoch 248/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6852e-06 - val_loss: 1.3398e-06\n",
      "Epoch 249/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6852e-06 - val_loss: 1.3398e-06\n",
      "Epoch 250/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6851e-06 - val_loss: 1.3398e-06\n",
      "Epoch 251/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6851e-06 - val_loss: 1.3398e-06\n",
      "Epoch 252/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6851e-06 - val_loss: 1.3398e-06\n",
      "Epoch 253/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6851e-06 - val_loss: 1.3398e-06\n",
      "Epoch 254/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6851e-06 - val_loss: 1.3398e-06\n",
      "Epoch 255/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6851e-06 - val_loss: 1.3398e-06\n",
      "Epoch 256/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6851e-06 - val_loss: 1.3397e-06\n",
      "Epoch 257/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6850e-06 - val_loss: 1.3397e-06\n",
      "Epoch 258/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6850e-06 - val_loss: 1.3397e-06\n",
      "Epoch 259/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6850e-06 - val_loss: 1.3397e-06\n",
      "Epoch 260/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6850e-06 - val_loss: 1.3397e-06\n",
      "Epoch 261/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6850e-06 - val_loss: 1.3397e-06\n",
      "Epoch 262/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6850e-06 - val_loss: 1.3397e-06\n",
      "Epoch 263/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6849e-06 - val_loss: 1.3397e-06\n",
      "Epoch 264/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6849e-06 - val_loss: 1.3396e-06\n",
      "Epoch 265/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6849e-06 - val_loss: 1.3396e-06\n",
      "Epoch 266/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6849e-06 - val_loss: 1.3396e-06\n",
      "Epoch 267/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6849e-06 - val_loss: 1.3396e-06\n",
      "Epoch 268/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6849e-06 - val_loss: 1.3396e-06\n",
      "Epoch 269/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6848e-06 - val_loss: 1.3396e-06\n",
      "Epoch 270/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6848e-06 - val_loss: 1.3396e-06\n",
      "Epoch 271/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6848e-06 - val_loss: 1.3396e-06\n",
      "Epoch 272/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6848e-06 - val_loss: 1.3396e-06\n",
      "Epoch 273/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6848e-06 - val_loss: 1.3395e-06\n",
      "Epoch 274/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6848e-06 - val_loss: 1.3395e-06\n",
      "Epoch 275/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6847e-06 - val_loss: 1.3395e-06\n",
      "Epoch 276/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6847e-06 - val_loss: 1.3395e-06\n",
      "Epoch 277/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6847e-06 - val_loss: 1.3395e-06\n",
      "Epoch 278/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6847e-06 - val_loss: 1.3395e-06\n",
      "Epoch 279/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6847e-06 - val_loss: 1.3395e-06\n",
      "Epoch 280/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6847e-06 - val_loss: 1.3395e-06\n",
      "Epoch 281/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6846e-06 - val_loss: 1.3394e-06\n",
      "Epoch 282/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6846e-06 - val_loss: 1.3394e-06\n",
      "Epoch 283/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6846e-06 - val_loss: 1.3394e-06\n",
      "Epoch 284/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6846e-06 - val_loss: 1.3394e-06\n",
      "Epoch 285/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6846e-06 - val_loss: 1.3394e-06\n",
      "Epoch 286/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6846e-06 - val_loss: 1.3394e-06\n",
      "Epoch 287/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6845e-06 - val_loss: 1.3394e-06\n",
      "Epoch 288/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6845e-06 - val_loss: 1.3394e-06\n",
      "Epoch 289/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6845e-06 - val_loss: 1.3393e-06\n",
      "Epoch 290/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6845e-06 - val_loss: 1.3393e-06\n",
      "Epoch 291/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6845e-06 - val_loss: 1.3393e-06\n",
      "Epoch 292/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6845e-06 - val_loss: 1.3393e-06\n",
      "Epoch 293/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6844e-06 - val_loss: 1.3393e-06\n",
      "Epoch 294/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6844e-06 - val_loss: 1.3393e-06\n",
      "Epoch 295/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6844e-06 - val_loss: 1.3393e-06\n",
      "Epoch 296/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6844e-06 - val_loss: 1.3393e-06\n",
      "Epoch 297/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6844e-06 - val_loss: 1.3392e-06\n",
      "Epoch 298/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6843e-06 - val_loss: 1.3392e-06\n",
      "Epoch 299/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6843e-06 - val_loss: 1.3392e-06\n",
      "Epoch 300/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6843e-06 - val_loss: 1.3392e-06\n",
      "Epoch 301/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6843e-06 - val_loss: 1.3392e-06\n",
      "Epoch 302/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6843e-06 - val_loss: 1.3392e-06\n",
      "Epoch 303/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6843e-06 - val_loss: 1.3392e-06\n",
      "Epoch 304/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6842e-06 - val_loss: 1.3391e-06\n",
      "Epoch 305/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6842e-06 - val_loss: 1.3391e-06\n",
      "Epoch 306/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6842e-06 - val_loss: 1.3391e-06\n",
      "Epoch 307/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6842e-06 - val_loss: 1.3391e-06\n",
      "Epoch 308/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6842e-06 - val_loss: 1.3391e-06\n",
      "Epoch 309/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6841e-06 - val_loss: 1.3391e-06\n",
      "Epoch 310/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6841e-06 - val_loss: 1.3391e-06\n",
      "Epoch 311/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6841e-06 - val_loss: 1.3391e-06\n",
      "Epoch 312/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6841e-06 - val_loss: 1.3390e-06\n",
      "Epoch 313/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6841e-06 - val_loss: 1.3390e-06\n",
      "Epoch 314/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6841e-06 - val_loss: 1.3390e-06\n",
      "Epoch 315/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6840e-06 - val_loss: 1.3390e-06\n",
      "Epoch 316/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6840e-06 - val_loss: 1.3390e-06\n",
      "Epoch 317/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6840e-06 - val_loss: 1.3390e-06\n",
      "Epoch 318/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6840e-06 - val_loss: 1.3390e-06\n",
      "Epoch 319/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6840e-06 - val_loss: 1.3389e-06\n",
      "Epoch 320/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6839e-06 - val_loss: 1.3389e-06\n",
      "Epoch 321/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6839e-06 - val_loss: 1.3389e-06\n",
      "Epoch 322/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6839e-06 - val_loss: 1.3389e-06\n",
      "Epoch 323/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6839e-06 - val_loss: 1.3389e-06\n",
      "Epoch 324/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6839e-06 - val_loss: 1.3389e-06\n",
      "Epoch 325/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6838e-06 - val_loss: 1.3389e-06\n",
      "Epoch 326/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6838e-06 - val_loss: 1.3388e-06\n",
      "Epoch 327/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6838e-06 - val_loss: 1.3388e-06\n",
      "Epoch 328/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6838e-06 - val_loss: 1.3388e-06\n",
      "Epoch 329/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6838e-06 - val_loss: 1.3388e-06\n",
      "Epoch 330/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6837e-06 - val_loss: 1.3388e-06\n",
      "Epoch 331/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6837e-06 - val_loss: 1.3388e-06\n",
      "Epoch 332/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6837e-06 - val_loss: 1.3388e-06\n",
      "Epoch 333/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6837e-06 - val_loss: 1.3387e-06\n",
      "Epoch 334/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6837e-06 - val_loss: 1.3387e-06\n",
      "Epoch 335/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6836e-06 - val_loss: 1.3387e-06\n",
      "Epoch 336/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6836e-06 - val_loss: 1.3387e-06\n",
      "Epoch 337/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6836e-06 - val_loss: 1.3387e-06\n",
      "Epoch 338/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6836e-06 - val_loss: 1.3387e-06\n",
      "Epoch 339/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6836e-06 - val_loss: 1.3387e-06\n",
      "Epoch 340/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6835e-06 - val_loss: 1.3386e-06\n",
      "Epoch 341/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6835e-06 - val_loss: 1.3386e-06\n",
      "Epoch 342/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6835e-06 - val_loss: 1.3386e-06\n",
      "Epoch 343/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6835e-06 - val_loss: 1.3386e-06\n",
      "Epoch 344/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6834e-06 - val_loss: 1.3386e-06\n",
      "Epoch 345/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6834e-06 - val_loss: 1.3386e-06\n",
      "Epoch 346/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6834e-06 - val_loss: 1.3386e-06\n",
      "Epoch 347/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6834e-06 - val_loss: 1.3385e-06\n",
      "Epoch 348/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6834e-06 - val_loss: 1.3385e-06\n",
      "Epoch 349/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6833e-06 - val_loss: 1.3385e-06\n",
      "Epoch 350/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6833e-06 - val_loss: 1.3385e-06\n",
      "Epoch 351/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6833e-06 - val_loss: 1.3385e-06\n",
      "Epoch 352/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6833e-06 - val_loss: 1.3385e-06\n",
      "Epoch 353/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6833e-06 - val_loss: 1.3385e-06\n",
      "Epoch 354/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6832e-06 - val_loss: 1.3384e-06\n",
      "Epoch 355/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6832e-06 - val_loss: 1.3384e-06\n",
      "Epoch 356/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6832e-06 - val_loss: 1.3384e-06\n",
      "Epoch 357/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6832e-06 - val_loss: 1.3384e-06\n",
      "Epoch 358/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6831e-06 - val_loss: 1.3384e-06\n",
      "Epoch 359/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6831e-06 - val_loss: 1.3384e-06\n",
      "Epoch 360/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6831e-06 - val_loss: 1.3383e-06\n",
      "Epoch 361/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6831e-06 - val_loss: 1.3383e-06\n",
      "Epoch 362/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6831e-06 - val_loss: 1.3383e-06\n",
      "Epoch 363/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6830e-06 - val_loss: 1.3383e-06\n",
      "Epoch 364/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6830e-06 - val_loss: 1.3383e-06\n",
      "Epoch 365/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6830e-06 - val_loss: 1.3383e-06\n",
      "Epoch 366/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6830e-06 - val_loss: 1.3382e-06\n",
      "Epoch 367/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6829e-06 - val_loss: 1.3382e-06\n",
      "Epoch 368/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6829e-06 - val_loss: 1.3382e-06\n",
      "Epoch 369/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6829e-06 - val_loss: 1.3382e-06\n",
      "Epoch 370/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6829e-06 - val_loss: 1.3382e-06\n",
      "Epoch 371/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6828e-06 - val_loss: 1.3382e-06\n",
      "Epoch 372/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6828e-06 - val_loss: 1.3381e-06\n",
      "Epoch 373/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6828e-06 - val_loss: 1.3381e-06\n",
      "Epoch 374/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6828e-06 - val_loss: 1.3381e-06\n",
      "Epoch 375/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6827e-06 - val_loss: 1.3381e-06\n",
      "Epoch 376/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6827e-06 - val_loss: 1.3381e-06\n",
      "Epoch 377/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6827e-06 - val_loss: 1.3381e-06\n",
      "Epoch 378/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6827e-06 - val_loss: 1.3381e-06\n",
      "Epoch 379/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6827e-06 - val_loss: 1.3380e-06\n",
      "Epoch 380/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6826e-06 - val_loss: 1.3380e-06\n",
      "Epoch 381/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6826e-06 - val_loss: 1.3380e-06\n",
      "Epoch 382/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6826e-06 - val_loss: 1.3380e-06\n",
      "Epoch 383/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6826e-06 - val_loss: 1.3380e-06\n",
      "Epoch 384/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6825e-06 - val_loss: 1.3379e-06\n",
      "Epoch 385/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.6825e-06 - val_loss: 1.3379e-06\n",
      "Epoch 386/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6825e-06 - val_loss: 1.3379e-06\n",
      "Epoch 387/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6825e-06 - val_loss: 1.3379e-06\n",
      "Epoch 388/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6824e-06 - val_loss: 1.3379e-06\n",
      "Epoch 389/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6824e-06 - val_loss: 1.3379e-06\n",
      "Epoch 390/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6824e-06 - val_loss: 1.3378e-06\n",
      "Epoch 391/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6824e-06 - val_loss: 1.3378e-06\n",
      "Epoch 392/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6823e-06 - val_loss: 1.3378e-06\n",
      "Epoch 393/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6823e-06 - val_loss: 1.3378e-06\n",
      "Epoch 394/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6823e-06 - val_loss: 1.3378e-06\n",
      "Epoch 395/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6822e-06 - val_loss: 1.3378e-06\n",
      "Epoch 396/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6822e-06 - val_loss: 1.3377e-06\n",
      "Epoch 397/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6822e-06 - val_loss: 1.3377e-06\n",
      "Epoch 398/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6822e-06 - val_loss: 1.3377e-06\n",
      "Epoch 399/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6821e-06 - val_loss: 1.3377e-06\n",
      "Epoch 400/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6821e-06 - val_loss: 1.3377e-06\n",
      "Epoch 401/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6821e-06 - val_loss: 1.3376e-06\n",
      "Epoch 402/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6821e-06 - val_loss: 1.3376e-06\n",
      "Epoch 403/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6820e-06 - val_loss: 1.3376e-06\n",
      "Epoch 404/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6820e-06 - val_loss: 1.3376e-06\n",
      "Epoch 405/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6820e-06 - val_loss: 1.3376e-06\n",
      "Epoch 406/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6820e-06 - val_loss: 1.3376e-06\n",
      "Epoch 407/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6819e-06 - val_loss: 1.3375e-06\n",
      "Epoch 408/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6819e-06 - val_loss: 1.3375e-06\n",
      "Epoch 409/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6819e-06 - val_loss: 1.3375e-06\n",
      "Epoch 410/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6818e-06 - val_loss: 1.3375e-06\n",
      "Epoch 411/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6818e-06 - val_loss: 1.3375e-06\n",
      "Epoch 412/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6818e-06 - val_loss: 1.3374e-06\n",
      "Epoch 413/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6818e-06 - val_loss: 1.3374e-06\n",
      "Epoch 414/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6817e-06 - val_loss: 1.3374e-06\n",
      "Epoch 415/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6817e-06 - val_loss: 1.3374e-06\n",
      "Epoch 416/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6817e-06 - val_loss: 1.3374e-06\n",
      "Epoch 417/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6817e-06 - val_loss: 1.3374e-06\n",
      "Epoch 418/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6816e-06 - val_loss: 1.3373e-06\n",
      "Epoch 419/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6816e-06 - val_loss: 1.3373e-06\n",
      "Epoch 420/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6816e-06 - val_loss: 1.3373e-06\n",
      "Epoch 421/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6815e-06 - val_loss: 1.3373e-06\n",
      "Epoch 422/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6815e-06 - val_loss: 1.3373e-06\n",
      "Epoch 423/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6815e-06 - val_loss: 1.3372e-06\n",
      "Epoch 424/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6814e-06 - val_loss: 1.3372e-06\n",
      "Epoch 425/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6814e-06 - val_loss: 1.3372e-06\n",
      "Epoch 426/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6814e-06 - val_loss: 1.3372e-06\n",
      "Epoch 427/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6814e-06 - val_loss: 1.3372e-06\n",
      "Epoch 428/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6813e-06 - val_loss: 1.3371e-06\n",
      "Epoch 429/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6813e-06 - val_loss: 1.3371e-06\n",
      "Epoch 430/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6813e-06 - val_loss: 1.3371e-06\n",
      "Epoch 431/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6812e-06 - val_loss: 1.3371e-06\n",
      "Epoch 432/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6812e-06 - val_loss: 1.3371e-06\n",
      "Epoch 433/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6812e-06 - val_loss: 1.3370e-06\n",
      "Epoch 434/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6811e-06 - val_loss: 1.3370e-06\n",
      "Epoch 435/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6811e-06 - val_loss: 1.3370e-06\n",
      "Epoch 436/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6811e-06 - val_loss: 1.3370e-06\n",
      "Epoch 437/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6811e-06 - val_loss: 1.3369e-06\n",
      "Epoch 438/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6810e-06 - val_loss: 1.3369e-06\n",
      "Epoch 439/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6810e-06 - val_loss: 1.3369e-06\n",
      "Epoch 440/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6810e-06 - val_loss: 1.3369e-06\n",
      "Epoch 441/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6809e-06 - val_loss: 1.3369e-06\n",
      "Epoch 442/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6809e-06 - val_loss: 1.3368e-06\n",
      "Epoch 443/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6809e-06 - val_loss: 1.3368e-06\n",
      "Epoch 444/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6808e-06 - val_loss: 1.3368e-06\n",
      "Epoch 445/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6808e-06 - val_loss: 1.3368e-06\n",
      "Epoch 446/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6808e-06 - val_loss: 1.3368e-06\n",
      "Epoch 447/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6807e-06 - val_loss: 1.3367e-06\n",
      "Epoch 448/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6807e-06 - val_loss: 1.3367e-06\n",
      "Epoch 449/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6807e-06 - val_loss: 1.3367e-06\n",
      "Epoch 450/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6806e-06 - val_loss: 1.3367e-06\n",
      "Epoch 451/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6806e-06 - val_loss: 1.3366e-06\n",
      "Epoch 452/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6806e-06 - val_loss: 1.3366e-06\n",
      "Epoch 453/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6805e-06 - val_loss: 1.3366e-06\n",
      "Epoch 454/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6805e-06 - val_loss: 1.3366e-06\n",
      "Epoch 455/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6805e-06 - val_loss: 1.3366e-06\n",
      "Epoch 456/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6804e-06 - val_loss: 1.3365e-06\n",
      "Epoch 457/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6804e-06 - val_loss: 1.3365e-06\n",
      "Epoch 458/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6804e-06 - val_loss: 1.3365e-06\n",
      "Epoch 459/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6803e-06 - val_loss: 1.3365e-06\n",
      "Epoch 460/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6803e-06 - val_loss: 1.3364e-06\n",
      "Epoch 461/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6803e-06 - val_loss: 1.3364e-06\n",
      "Epoch 462/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6802e-06 - val_loss: 1.3364e-06\n",
      "Epoch 463/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6802e-06 - val_loss: 1.3364e-06\n",
      "Epoch 464/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6801e-06 - val_loss: 1.3364e-06\n",
      "Epoch 465/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6801e-06 - val_loss: 1.3363e-06\n",
      "Epoch 466/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6801e-06 - val_loss: 1.3363e-06\n",
      "Epoch 467/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6800e-06 - val_loss: 1.3363e-06\n",
      "Epoch 468/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6800e-06 - val_loss: 1.3363e-06\n",
      "Epoch 469/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6800e-06 - val_loss: 1.3362e-06\n",
      "Epoch 470/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6799e-06 - val_loss: 1.3362e-06\n",
      "Epoch 471/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6799e-06 - val_loss: 1.3362e-06\n",
      "Epoch 472/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6799e-06 - val_loss: 1.3362e-06\n",
      "Epoch 473/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6798e-06 - val_loss: 1.3361e-06\n",
      "Epoch 474/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6798e-06 - val_loss: 1.3361e-06\n",
      "Epoch 475/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6797e-06 - val_loss: 1.3361e-06\n",
      "Epoch 476/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6797e-06 - val_loss: 1.3361e-06\n",
      "Epoch 477/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6797e-06 - val_loss: 1.3360e-06\n",
      "Epoch 478/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6796e-06 - val_loss: 1.3360e-06\n",
      "Epoch 479/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6796e-06 - val_loss: 1.3360e-06\n",
      "Epoch 480/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6795e-06 - val_loss: 1.3360e-06\n",
      "Epoch 481/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6795e-06 - val_loss: 1.3359e-06\n",
      "Epoch 482/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6795e-06 - val_loss: 1.3359e-06\n",
      "Epoch 483/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6794e-06 - val_loss: 1.3359e-06\n",
      "Epoch 484/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6794e-06 - val_loss: 1.3359e-06\n",
      "Epoch 485/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6794e-06 - val_loss: 1.3358e-06\n",
      "Epoch 486/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6793e-06 - val_loss: 1.3358e-06\n",
      "Epoch 487/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6793e-06 - val_loss: 1.3358e-06\n",
      "Epoch 488/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6792e-06 - val_loss: 1.3358e-06\n",
      "Epoch 489/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6792e-06 - val_loss: 1.3357e-06\n",
      "Epoch 490/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6791e-06 - val_loss: 1.3357e-06\n",
      "Epoch 491/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6791e-06 - val_loss: 1.3357e-06\n",
      "Epoch 492/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6791e-06 - val_loss: 1.3356e-06\n",
      "Epoch 493/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6790e-06 - val_loss: 1.3356e-06\n",
      "Epoch 494/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6790e-06 - val_loss: 1.3356e-06\n",
      "Epoch 495/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6789e-06 - val_loss: 1.3356e-06\n",
      "Epoch 496/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6789e-06 - val_loss: 1.3355e-06\n",
      "Epoch 497/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6789e-06 - val_loss: 1.3355e-06\n",
      "Epoch 498/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6788e-06 - val_loss: 1.3355e-06\n",
      "Epoch 499/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6788e-06 - val_loss: 1.3355e-06\n",
      "Epoch 500/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6787e-06 - val_loss: 1.3354e-06\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "epochs_n = 500\n",
    "hist = autoencoder.fit(x_train_noisy, \n",
    "                       x_train, \n",
    "                       epochs=epochs_n, \n",
    "                       batch_size=batch_size_n, \n",
    "                       shuffle=True, \n",
    "                       validation_data=(x_test_noisy, x_test), verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4718b96c",
   "metadata": {},
   "source": [
    "## Calculate exposures\n",
    "This chunk calculates encoding and decoding weights.  NB: these can be negative!!!! They do not specify what constitutes the exposures. Nowhere in the provided script are the signature matrix generated, but they do provide a tsv of generated signatures in the github we dont know where come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae66ca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Biliary-AdenoCA::SP117655  Biliary-AdenoCA::SP117556  \\\n",
      "encodings                                                         \n",
      "1                          -0.033410                  -0.028750   \n",
      "2                          -0.007186                   0.016034   \n",
      "3                          -0.018382                  -0.012436   \n",
      "4                          -0.013300                   0.007429   \n",
      "5                          -0.045177                  -0.001184   \n",
      "\n",
      "           Biliary-AdenoCA::SP117627  Biliary-AdenoCA::SP117775  \n",
      "encodings                                                        \n",
      "1                          -0.041790                  -0.015291  \n",
      "2                          -0.042951                  -0.043452  \n",
      "3                          -0.045344                   0.003034  \n",
      "4                          -0.040786                   0.041602  \n",
      "5                          -0.001454                  -0.013474  \n",
      "           Biliary-AdenoCA::SP117655  Biliary-AdenoCA::SP117556  \\\n",
      "decodings                                                         \n",
      "1                           0.019370                   0.017013   \n",
      "2                          -0.045760                   0.024025   \n",
      "3                          -0.029567                  -0.009685   \n",
      "4                           0.024137                   0.016782   \n",
      "5                          -0.044771                   0.031502   \n",
      "\n",
      "           Biliary-AdenoCA::SP117627  Biliary-AdenoCA::SP117775  \n",
      "decodings                                                        \n",
      "1                           0.001891                  -0.042585  \n",
      "2                          -0.039071                  -0.046138  \n",
      "3                           0.001688                  -0.005012  \n",
      "4                          -0.026715                  -0.018131  \n",
      "5                          -0.006259                   0.024805  \n",
      "(1536, 5)\n"
     ]
    }
   ],
   "source": [
    "weights = []\n",
    "for layer in encoder.layers: #seems redundant with only one layer\n",
    "        weights.append(layer.get_weights())\n",
    "        \n",
    "weight_layer_df = pd.DataFrame(np.transpose(weights[1][0]), columns=mf_df.columns, index=range(1, latent_dim+1))\n",
    "weight_layer_df.index.name = 'encodings'\n",
    "#print encodings of the first 4 observations\n",
    "print(weight_layer_df.iloc[:,0:4])\n",
    "\n",
    "weights = []\n",
    "for layer in decoder.layers:\n",
    "        weights.append(layer.get_weights())\n",
    "weight_layer_df = pd.DataFrame(weights[1][0], columns=mf_df.columns, index=range(1, latent_dim+1))\n",
    "weight_layer_df.index.name = 'decodings'\n",
    "#print decodings of the first 4 observations\n",
    "print(weight_layer_df.iloc[:,0:4])\n",
    "\n",
    "#Her prver jeg at generere signaturerne ved at bruge den trnede encoder model p hele datasttet.\n",
    "#Det fr strrelsen 1536xnsigs fordi deres SBS input er pentanucleotiden for at f nok observationer til at trne.\n",
    "sigs = pd.DataFrame(encoder.predict(mf_df))\n",
    "print(sigs.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28bd51e",
   "metadata": {},
   "source": [
    "## Plot the results\n",
    "Now we need to compress the 1536xnsigs siganture matrix into a 96xnsigs signature matrix, by summing up the the values in each trinucleotide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d007ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trinucleotide</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A[C&gt;A]A</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>309.536194</td>\n",
       "      <td>760.494629</td>\n",
       "      <td>1087.757324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C[C&gt;A]T</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3945.616455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1781.150513</td>\n",
       "      <td>362.964600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C[C&gt;A]G</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317177</td>\n",
       "      <td>19.151955</td>\n",
       "      <td>216.339691</td>\n",
       "      <td>268.940338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C[C&gt;A]C</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.764324</td>\n",
       "      <td>54.924515</td>\n",
       "      <td>1105.370361</td>\n",
       "      <td>743.149109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C[C&gt;A]A</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.188156</td>\n",
       "      <td>104.718262</td>\n",
       "      <td>905.826965</td>\n",
       "      <td>1285.406860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A[T&gt;G]G</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>183.085480</td>\n",
       "      <td>6.772204</td>\n",
       "      <td>1.185161</td>\n",
       "      <td>240.478256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A[T&gt;G]C</th>\n",
       "      <td>0.065294</td>\n",
       "      <td>377.825531</td>\n",
       "      <td>44.820118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>309.168304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A[T&gt;G]A</th>\n",
       "      <td>176.546997</td>\n",
       "      <td>395.901978</td>\n",
       "      <td>72.900475</td>\n",
       "      <td>1.434479</td>\n",
       "      <td>544.100220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G[T&gt;G]T</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>837.142334</td>\n",
       "      <td>0.224898</td>\n",
       "      <td>94.679466</td>\n",
       "      <td>535.326965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T[T&gt;G]T</th>\n",
       "      <td>6606.280273</td>\n",
       "      <td>11595.159180</td>\n",
       "      <td>5241.649902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14871.737305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0             1            2            3  \\\n",
       "Trinucleotide                                                        \n",
       "A[C>A]A           0.000000      0.000000   309.536194   760.494629   \n",
       "C[C>A]T           0.000000   3945.616455     0.000000  1781.150513   \n",
       "C[C>A]G           0.000000      0.317177    19.151955   216.339691   \n",
       "C[C>A]C           0.000000     21.764324    54.924515  1105.370361   \n",
       "C[C>A]A           0.000000     71.188156   104.718262   905.826965   \n",
       "...                    ...           ...          ...          ...   \n",
       "A[T>G]G           0.000000    183.085480     6.772204     1.185161   \n",
       "A[T>G]C           0.065294    377.825531    44.820118     0.000000   \n",
       "A[T>G]A         176.546997    395.901978    72.900475     1.434479   \n",
       "G[T>G]T           0.000000    837.142334     0.224898    94.679466   \n",
       "T[T>G]T        6606.280273  11595.159180  5241.649902     0.000000   \n",
       "\n",
       "                          4  \n",
       "Trinucleotide                \n",
       "A[C>A]A         1087.757324  \n",
       "C[C>A]T          362.964600  \n",
       "C[C>A]G          268.940338  \n",
       "C[C>A]C          743.149109  \n",
       "C[C>A]A         1285.406860  \n",
       "...                     ...  \n",
       "A[T>G]G          240.478256  \n",
       "A[T>G]C          309.168304  \n",
       "A[T>G]A          544.100220  \n",
       "G[T>G]T          535.326965  \n",
       "T[T>G]T        14871.737305  \n",
       "\n",
       "[96 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tri = [p[1] +\"[\" + m + \"]\" + p[3] for (m,p) in zip(mutation,penta)]\n",
    " \n",
    "sigs['Mutation type'] = mutation\n",
    "sigs['Trinucleotide'] = tri\n",
    "sigs['Pentanucleotide'] = penta\n",
    "sigs\n",
    "\n",
    "sigs96 = pd.DataFrame(sigs.groupby('Trinucleotide').sum())\n",
    "sigs96['Mutation'] = [s[2:5] for s in sigs96.index]\n",
    "sigs96 = sigs96.sort_values('Mutation')\n",
    "trinucleotide = sigs96.index\n",
    "mutation = sigs96['Mutation']\n",
    "sigs96 = sigs96.drop('Mutation', axis = 1)\n",
    "\n",
    "sigs96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d7a034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the results\n",
    "def plotsigs(context, mutation, signatures, nsigs, title):\n",
    "    colors = {'C>A': 'r', 'C>G': 'b', 'C>T': 'g', \n",
    "                'T>A' : 'y', 'T>C': 'c','T>G' : 'm' }\n",
    "    labels = list(colors.keys())\n",
    "    handles = [plt.Rectangle((0,0),1,1, color=colors[label]) for label in labels]\n",
    "    for i in range(nsigs):\n",
    "        plt.subplot(nsigs,1, (i+1))\n",
    "        #plt.figure(figsize=(20,7))\n",
    "        plt.bar(x = context, \n",
    "                height =  signatures[:,i]/np.sum(signatures[:,i]), \n",
    "                color = [colors[i] for i in mutation])\n",
    "        plt.xticks([])\n",
    "        if i == 0:\n",
    "            plt.title(title)\n",
    "    #plt.legend(handles,labels)\n",
    "    #plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotsigs(trinucleotide, mutation, sigs96.to_numpy(), nsigs, \"AE signatures\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ce34b4",
   "metadata": {},
   "source": [
    "Det  her ser selvflgelig lidt fjollet ud, men det er ogs fordi vi har forsgt at beskrive hele PCAWG med 5 signaturer. Men det er sdan her metoden fungerer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
