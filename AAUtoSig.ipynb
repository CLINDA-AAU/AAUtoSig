{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba41f62",
   "metadata": {},
   "source": [
    "## AAUtoSig Markdown\n",
    "This document is a runthrough of our autoencoder model.\n",
    "Firstly we initialise our installed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65fa826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.spatial as sp\n",
    "import random\n",
    "\n",
    "from functions import simulate_counts, plotsigs, cosine_perm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e5bb6f",
   "metadata": {},
   "source": [
    "## Initialise the autoencoder\n",
    "The following block creates a class to initialize a one-hidden-layer linear autoencoder, and a method for traning the one such model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec40baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMFAE(torch.nn.Module):\n",
    "    def __init__(self, dim1):\n",
    "    \n",
    "        super().__init__()\n",
    "\n",
    "        # Building an linear encoder\n",
    "        # 96 => dim1\n",
    "        self.enc1 = torch.nn.Linear(1536, dim1, bias = False)\n",
    "          \n",
    "        # Building an linear decoder \n",
    "        # dim1 ==> 96\n",
    "        self.dec1 = torch.nn.Linear(dim1, 1536, bias = False)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.enc1(x)\n",
    "        x = self.dec1(x)\n",
    "        return x\n",
    "        \n",
    "    # Model Initialization\n",
    "                                \n",
    "def train_NMFAE(epochs, model, x_train, loss_function, optimizer, batch_size):\n",
    "    \n",
    "    #turn the training data into a tensor\n",
    "    x_train_tensor = torch.tensor(x_train.values, \n",
    "                              dtype = torch.float32)\n",
    "    \n",
    "    #this is what loads makes the updates batch-wise insted of the full data matrix\n",
    "    trainloader = torch.utils.data.DataLoader(x_train_tensor, \n",
    "                                              batch_size=batch_size, \n",
    "                                              shuffle=True)\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        model.train() #set model in traning mode (alternative model.eval())\n",
    "        \n",
    "        for data in trainloader:\n",
    "          # Output of Autoencoder\n",
    "          reconstructed = model(data)\n",
    "            \n",
    "          # Calculating the loss function\n",
    "          loss = loss_function(reconstructed, data)\n",
    "\n",
    "\n",
    "          optimizer.zero_grad() #clear old gradients\n",
    "          loss.backward() #backpropagation\n",
    "          optimizer.step() #update params\n",
    "        #constrain the weights of the decoding layer to be non-negative  \n",
    "        with torch.no_grad():\n",
    "            for p in model.dec1.weight:\n",
    "                p.clamp_(min = 0)\n",
    "        \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af9b6f8",
   "metadata": {},
   "source": [
    "## Application\n",
    "Now we can use our autoencoder on some simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95f02d71",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mq:\\AUH-HAEM-FORSK-MutSigDLBCL222\\article_1\\scripts\\AAUtoSig\\AAUtoSig.ipynb Cell 6'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000005?line=20'>21</a>\u001b[0m \u001b[39m# Using an Adam Optimizer with lr = 1e-3\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000005?line=21'>22</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000005?line=22'>23</a>\u001b[0m                             lr \u001b[39m=\u001b[39m \u001b[39m1e-3\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000005?line=24'>25</a>\u001b[0m train_NMFAE(epochs \u001b[39m=\u001b[39;49m \u001b[39m500\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000005?line=25'>26</a>\u001b[0m             model \u001b[39m=\u001b[39;49m model, \n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000005?line=26'>27</a>\u001b[0m             x_train \u001b[39m=\u001b[39;49m x_train, \n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000005?line=27'>28</a>\u001b[0m             loss_function \u001b[39m=\u001b[39;49m loss_function, \n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000005?line=28'>29</a>\u001b[0m             optimizer \u001b[39m=\u001b[39;49m optimizer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000005?line=29'>30</a>\u001b[0m             batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000005?line=32'>33</a>\u001b[0m \u001b[39m#the weights of the decoding layer (dec1) is where we find the signatures.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000005?line=33'>34</a>\u001b[0m sigs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdec1\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata    \n",
      "\u001b[1;32mq:\\AUH-HAEM-FORSK-MutSigDLBCL222\\article_1\\scripts\\AAUtoSig\\AAUtoSig.ipynb Cell 4'\u001b[0m in \u001b[0;36mtrain_NMFAE\u001b[1;34m(epochs, model, x_train, loss_function, optimizer, batch_size)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000003?line=33'>34</a>\u001b[0m model\u001b[39m.\u001b[39mtrain() \u001b[39m#set model in traning mode (alternative model.eval())\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000003?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m trainloader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000003?line=36'>37</a>\u001b[0m   \u001b[39m# Output of Autoencoder\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000003?line=37'>38</a>\u001b[0m   reconstructed \u001b[39m=\u001b[39m model(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000003?line=39'>40</a>\u001b[0m   \u001b[39m# Calculating the loss function\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000003?line=40'>41</a>\u001b[0m   loss \u001b[39m=\u001b[39m loss_function(reconstructed, data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mq:\\AUH-HAEM-FORSK-MutSigDLBCL222\\article_1\\scripts\\AAUtoSig\\AAUtoSig.ipynb Cell 4'\u001b[0m in \u001b[0;36mNMFAE.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000003?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000003?line=15'>16</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menc1(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000003?line=16'>17</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdec1(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/AUH-HAEM-FORSK-MutSigDLBCL222/article_1/scripts/AAUtoSig/AAUtoSig.ipynb#ch0000003?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\functional.py:1848\u001b[0m, in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/functional.py?line=1845'>1846</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight, bias):\n\u001b[0;32m   <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/functional.py?line=1846'>1847</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[39minput\u001b[39m, weight, bias), \u001b[39minput\u001b[39m, weight, bias\u001b[39m=\u001b[39mbias)\n\u001b[1;32m-> <a href='file:///c%3A/Users/bjyw/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/functional.py?line=1847'>1848</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, weight, bias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nsigs = 5\n",
    "\n",
    "np.random.seed(20)\n",
    "random.seed(20)\n",
    "mf_df, true_sigs,_ = simulate_counts(5,3000, pentanucelotide = True)\n",
    "penta = mf_df.index\n",
    "mutation = [p[3:6] for p in penta]\n",
    "\n",
    "X = mf_df.transpose()\n",
    "\n",
    "#80/20 train/validation split\n",
    "x_train = X.sample(frac=0.8)\n",
    "x_val = X.drop(x_train.index)\n",
    "\n",
    "#choosing the 'true' number of signatures\n",
    "model = NMFAE(dim1 = nsigs)\n",
    "\n",
    "# Validation using MSE Loss function\n",
    "loss_function = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Using an Adam Optimizer with lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            lr = 1e-3)\n",
    "                            \n",
    "train_NMFAE(epochs = 500, \n",
    "            model = model, \n",
    "            x_train = x_train, \n",
    "            loss_function = loss_function, \n",
    "            optimizer = optimizer,\n",
    "            batch_size=16)\n",
    "\n",
    "\n",
    "#the weights of the decoding layer (dec1) is where we find the signatures.\n",
    "sigs = model.dec1.weight.data    \n",
    "sigs = pd.DataFrame(sigs.numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d690518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri = [p[1:8] for p in penta]\n",
    "sigs['Mutation type'] = mutation\n",
    "sigs['Trinucleotide'] = tri\n",
    "sigs['Pentanucleotide'] = penta\n",
    "sigs\n",
    "\n",
    "sigs96 = pd.DataFrame(sigs.groupby('Trinucleotide').sum())\n",
    "sigs96['Mutation'] = [s[2:5] for s in sigs96.index]\n",
    "sigs96 = sigs96.sort_values('Mutation')\n",
    "trinucleotide = sigs96.index\n",
    "mutation = sigs96['Mutation']\n",
    "sigs96 = sigs96.drop('Mutation', axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "true_sigs['Trinucleotide'] = tri\n",
    "true_sigs96 = pd.DataFrame(true_sigs.groupby('Trinucleotide').sum())\n",
    "true_sigs96['Mutation'] = [s[2:5] for s in true_sigs96.index]\n",
    "true_sigs96 = true_sigs96.sort_values('Mutation')\n",
    "true_sigs96 = true_sigs96.drop('Mutation', axis = 1)\n",
    "\n",
    "perm = cosine_perm(sigs96.T,true_sigs96.T)\n",
    "sigs96 = sigs96[perm[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7a034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the results\n",
    "plotsigs(trinucleotide, mutation, sigs96.to_numpy(), nsigs, \"Estimated signatures\")  \n",
    "plotsigs(trinucleotide, mutation, true_sigs96.to_numpy(), nsigs, \"True signatures\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
