{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba41f62",
   "metadata": {},
   "source": [
    "## AAUtoSig Markdown\n",
    "This document is a runthrough of our autoencoder model.\n",
    "Firstly we initialise our installed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65fa826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.spatial as sp\n",
    "import random\n",
    "\n",
    "from random import sample\n",
    "from itertools import permutations\n",
    "from functions import simulate_counts, plotsigs, cosine_perm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e5bb6f",
   "metadata": {},
   "source": [
    "## Initialise the autoencoder\n",
    "The following block creates a class to initialize a one-hidden-layer linear autoencoder, and a method for traning the one such model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec40baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMFAE(torch.nn.Module):\n",
    "    def __init__(self, dim1):\n",
    "    \n",
    "        super().__init__()\n",
    "\n",
    "        # Building an linear encoder\n",
    "        # 96 => dim1\n",
    "        self.enc1 = torch.nn.Linear(1536, dim1, bias = False)\n",
    "          \n",
    "        # Building an linear decoder \n",
    "        # dim1 ==> 96\n",
    "        self.dec1 = torch.nn.Linear(dim1, 1536, bias = False)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.enc1(x)\n",
    "        x = self.dec1(x)\n",
    "        return x\n",
    "        \n",
    "    # Model Initialization\n",
    "                                \n",
    "def train_NMFAE(epochs, model, x_train, loss_function, optimizer, batch_size):\n",
    "    \n",
    "    #turn the training data into a tensor\n",
    "    x_train_tensor = torch.tensor(x_train.values, \n",
    "                              dtype = torch.float32)\n",
    "    \n",
    "    #this is what loads makes the updates batch-wise insted of the full data matrix\n",
    "    trainloader = torch.utils.data.DataLoader(x_train_tensor, \n",
    "                                              batch_size=batch_size, \n",
    "                                              shuffle=True)\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        model.train() #set model in traning mode (alternative model.eval())\n",
    "        \n",
    "        for data in trainloader:\n",
    "          # Output of Autoencoder\n",
    "          reconstructed = model(data)\n",
    "            \n",
    "          # Calculating the loss function\n",
    "          loss = loss_function(reconstructed, data)\n",
    "\n",
    "\n",
    "          optimizer.zero_grad() #clear old gradients\n",
    "          loss.backward() #backpropagation\n",
    "          optimizer.step() #update params\n",
    "        #constrain the weights of the decoding layer to be non-negative  \n",
    "        with torch.no_grad():\n",
    "            for p in model.dec1.weight:\n",
    "                p.clamp_(min = 0)\n",
    "        \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af9b6f8",
   "metadata": {},
   "source": [
    "## Application\n",
    "Now we can use our autoencoder on some simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f02d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsigs = 5\n",
    "\n",
    "np.random.seed(20)\n",
    "random.seed\n",
    "mf_df, true_sigs,_ = simulate_counts(5,3000, pentanucelotide = True)\n",
    "penta = mf_df.index\n",
    "mutation = [p[3:6] for p in penta]\n",
    "\n",
    "X = mf_df.transpose()\n",
    "\n",
    "#80/20 train/validation split\n",
    "x_train = X.sample(frac=0.8)\n",
    "x_val = X.drop(x_train.index)\n",
    "\n",
    "#choosing the 'true' number of signatures\n",
    "model = NMFAE(dim1 = nsigs)\n",
    "\n",
    "# Validation using MSE Loss function\n",
    "loss_function = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Using an Adam Optimizer with lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            lr = 1e-3)\n",
    "                            \n",
    "train_NMFAE(epochs = 500, \n",
    "            model = model, \n",
    "            x_train = x_train, \n",
    "            loss_function = loss_function, \n",
    "            optimizer = optimizer,\n",
    "            batch_size=16)\n",
    "\n",
    "\n",
    "#the weights of the decoding layer (dec1) is where we find the signatures.\n",
    "sigs = model.dec1.weight.data    \n",
    "sigs = pd.DataFrame(sigs.numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d690518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri = [p[1:8] for p in penta]\n",
    "sigs['Mutation type'] = mutation\n",
    "sigs['Trinucleotide'] = tri\n",
    "sigs['Pentanucleotide'] = penta\n",
    "sigs\n",
    "\n",
    "sigs96 = pd.DataFrame(sigs.groupby('Trinucleotide').sum())\n",
    "sigs96['Mutation'] = [s[2:5] for s in sigs96.index]\n",
    "sigs96 = sigs96.sort_values('Mutation')\n",
    "trinucleotide = sigs96.index\n",
    "mutation = sigs96['Mutation']\n",
    "sigs96 = sigs96.drop('Mutation', axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "true_sigs['Trinucleotide'] = tri\n",
    "true_sigs96 = pd.DataFrame(true_sigs.groupby('Trinucleotide').sum())\n",
    "true_sigs96['Mutation'] = [s[2:5] for s in true_sigs96.index]\n",
    "true_sigs96 = true_sigs96.sort_values('Mutation')\n",
    "true_sigs96 = true_sigs96.drop('Mutation', axis = 1)\n",
    "\n",
    "perm = cosine_perm(sigs96.T,true_sigs96.T)\n",
    "sigs96 = sigs96[perm[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the results\n",
    "plotsigs(trinucleotide, mutation, sigs96.to_numpy(), nsigs, \"Estimated signatures\")  \n",
    "plotsigs(trinucleotide, mutation, true_sigs96.to_numpy(), nsigs, \"True signatures\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
